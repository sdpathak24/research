{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stokes Inversion for GST/NIRIS Using Stacked Deep Neural Networks\n",
    "\n",
    "### Haodi Jiang et al.\n",
    "\n",
    "New Jersey Institute of Technology\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining high-quality magnetic and velocity fields through Stokes inversion is crucial in solar physics.\n",
    "Here, we present a new deep learning method, named Stacked Deep Neural Networks (SDNN),\n",
    "for inferring line-of-sight (LOS) velocities, Doppler widths and vector magnetic fields from Stokes profiles\n",
    "collected by the Near InfraRed Imaging Spectropolarimeter (NIRIS) on the 1.6 m Goode Solar Telescope (GST)\n",
    "at the Big Bear Solar Observatory (BBSO).\n",
    "\n",
    "In this notebook, we provide an overview of the SDNN project,\n",
    "detailing how it can be used to perform Stokes inversion for GST/NIRIS data.\n",
    "\n",
    "Since model training requires GPUs, it is omitted here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow of SDNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the SDDN has large model and fits files that can not be saved in public repository. Therefore, they must be downloaded first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the file: pretrained_model.h5 , please waint until it finishes.\n",
      "Finished dowloading the file.\n",
      "Downloading the file: inputs/cals_170713_162012.fts , please waint until it finishes.\n",
      "Finished dowloading the file.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "download_model()\n",
    "download_fits()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the load_model() function from SDNN module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SDNN model...\n",
      "Done Loading...\n"
     ]
    }
   ],
   "source": [
    "from SDNN import load_model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setup input and output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may set up your own data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_path = '/Users/sdpathak/Documents/njit/research/SDNN/inputs/'  # edit your input path\n",
    "output_path = '/Users/sdpathak/Documents/njit/research/SDNN/outputs'  # edit your output path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Predicting with Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import related libraries.\n",
    "\n",
    "Produce LOS velocities, Doppler widths, and vector magnetic fields by using the pretrained model.\n",
    "\n",
    "The code will also save b_total, inclination and azimuth if save_mag_field_o = True; otherwise it will only save bx, by, bz, Doppler width and LOS velocity.\n",
    "\n",
    "The predicted results will be saved in the given output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n",
      "Loading SDNN model...\n",
      "Done Loading...\n",
      "---------- Working on cals_170713_162012.fts ----------\n",
      "Loading test data...\n",
      "Done loading...\n",
      "Test data shape before reshape: (518400, 60, 4)\n",
      "Test data shape after reshape: (518400, 60, 4)\n",
      "Model input shape: (None, 60, 4)\n",
      "Start inversion...\n",
      "\u001b[1m16200/16200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 57ms/step\n",
      "End inversion...\n",
      "Inversion Time: 919.7 s\n",
      "Producing inversion results..\n",
      "Done saving..\n",
      "---------- Working on .gitignore ----------\n",
      "Error processing file .gitignore: Empty or corrupt FITS file\n"
     ]
    }
   ],
   "source": [
    "# from astropy.io import fits\n",
    "# import os\n",
    "# import time\n",
    "# import numpy as np\n",
    "# from SDNN import read_data\n",
    "# from SDNN import inverse\n",
    "# from SDNN import save_results\n",
    "# from SDNN import load_model\n",
    "\n",
    "# model = load_model()\n",
    "\n",
    "# for file in os.listdir(input_path):\n",
    "#     print('---------- working on', file, '----------')\n",
    "#     fits_file = os.path.join(input_path, file)\n",
    "#     hdu = fits.open(fits_file)\n",
    "#     hdu.verify('fix')\n",
    "#     data = hdu[0].data\n",
    "#     test_data, data_height, data_width = read_data(data)\n",
    "#     start = time.time()\n",
    "#     predict_results = inverse(test_data, model)\n",
    "#     end = time.time()\n",
    "#     print('Inversion Time:', np.round(end - start, 1), 's')\n",
    "#     save_results(predict_results, output_path, file[: file.find('.')], data_height, data_width, save_mag_field_o=False)\n",
    "\n",
    "from SDNN import load_model, read_data, inverse, save_results\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from astropy.io import fits\n",
    "\n",
    "# Define input and output paths\n",
    "input_path = '/Users/sdpathak/Documents/njit/research/SDNN/inputs/'\n",
    "output_path = '/Users/sdpathak/Documents/njit/research/SDNN/outputs/'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Load the model\n",
    "print(\"Loading the model...\")\n",
    "model = load_model()\n",
    "\n",
    "# Process each input file\n",
    "for file in os.listdir(input_path):\n",
    "    # if not file.endswith('.fts'):\n",
    "    #     print(f\"Skipping non-FITS file: {file}\")\n",
    "    #     continue\n",
    "\n",
    "    fits_file = os.path.join(input_path, file)\n",
    "    \n",
    "    try:\n",
    "        print(f\"---------- Working on {file} ----------\")\n",
    "        \n",
    "        # Open and verify the FITS file\n",
    "        hdu = fits.open(fits_file)\n",
    "        hdu.verify('fix')\n",
    "        data = hdu[0].data\n",
    "\n",
    "        # Preprocess the data\n",
    "        test_data, data_height, data_width = read_data(data)\n",
    "        \n",
    "        # Ensure test_data shape matches model input shape\n",
    "        print(f\"Test data shape before reshape: {test_data.shape}\")\n",
    "        \n",
    "        # Reshape test_data to match model input\n",
    "        test_data = np.reshape(test_data, (-1, 60, 4))  # Assuming model expects (batch_size, 60, 4)\n",
    "        print(f\"Test data shape after reshape: {test_data.shape}\")\n",
    "        print(f\"Model input shape: {model.input_shape}\")\n",
    "\n",
    "        # Perform prediction\n",
    "        start = time.time()\n",
    "        predict_results = inverse(test_data, model)\n",
    "        end = time.time()\n",
    "        print(f\"Inversion Time: {np.round(end - start, 1)} s\")\n",
    "\n",
    "        # Save the results\n",
    "        save_results(\n",
    "            predict_results, \n",
    "            output_path, \n",
    "            file[: file.find('.')],  # File name without extension\n",
    "            data_height, \n",
    "            data_width, \n",
    "            save_mag_field_o=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We develop a deep learning model (SDNN), which is an effective and alternative method for\n",
    "inferring LOS velocities, Doppler widths, and vector magnetic fields from Stokes profiles of GST/NIRIS.\n",
    "It is hoped that SDNN will be a useful tool in producing the high-quality velocity and\n",
    "magnetic fields that are crucial for understanding the evolution of physical properties of the solar atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "The authors gratefully acknowledge the use of data from the Goode Solar Telescope (GST) of the Big Bear Solar Observatory (BBSO).\n",
    "The BBSO operation is supported by NJIT and U.S. NSF grant AGS-1821294.\n",
    "This work was supported by U.S. NSF grants AGS-1927578, AGS-1954737, and AGS-2228996.\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "Inferring Line-of-sight Velocities and Doppler Widths from Stokes Profiles of GST/\n",
    "NIRIS Using Stacked Deep Neural Networks. Haodi Jiang et al 2022 ApJ 939 66\n",
    "\n",
    "https://iopscience.iop.org/article/10.3847/1538-4357/ac927e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
